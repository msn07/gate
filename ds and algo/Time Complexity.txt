Time Complexity:
================

	How to approximate an algorithm
	
	1. Iterative
		
		A() {
			for i=1 to n
			max(a, b)
		}
		
		if we are doing it in for, while, do..while it is generally called iterative algorithm
		
		In order to analyse such iterative program, we need to count the number of times a loop is going to executed.
		
	2. Recursive
	
			A(n) {
				if()
					A(n/2)
			}
			
		calling itself
		
		To analyze time taken by an recursive program, we use recursive iteration. i.e. we write a function of 'f(n)' in terms of f(n/2) 
		
		Analyze wise both are different.
		
		Any program that could be written using iteration could be written using Recursion and any recursion can be converted to iteration. So both are equivalent to each other.
		
		In case an algorithm does not contain either iteration or recursion, it means that, there is no dependency on the running time on the input size. i.e. whatever the input size, the running time is going to be constant value.
			
			O(1)
===========================================================================

	Examples:
	
	Iterative:
	
		1. 
		
		A() {
			int i
			for(i=1 to n)
				pf("sugu");
		}
		
		Total n times the line "sugu" will be printed, it means the complexity of the algorithm is O(n)
		
		in-case I having 
		
			for(i=1 to n)
				for(j=1 to n)
					pf("sugu");
			
			this case the time complexity of the program is O(n^2). If it is three loops the time complexity is n^3
		
		2. 
		A() {
			i = 1, s = 1;
			while(s <= n) {
				i++;
				s = s + i;
				pf("sugu")
			}
		} 
		
		how many times this while loop is going to executed.
		
		i is incremented in steps of 1(linear increment)
		s is get incremented by the value of i(depends)
		
		
		s 1 3 6 10 15....
		i 1 2 3 4  5 ....

		when is the entire loop going to stop, the value of s reaches n.
		
		Consider that particular value of s as K
			i.e. K <=n
		
			therefore what will the value of s
		
		if you observe, the s is incrementing depends on i
		
			so by the time i reaches K the value of s is K(K+1)/2(first ten natural numbers)
			
			K(K+1)/2 > n
			
			K = root 'n'
	
		3. 
		
			for(i=1;i^2<=n;i++)
				pf("ravi")
				
				i^2 <= n can written as i <= root n
			
			so the time complexity is O(root n)
			
			even u can write it as theta(root n) - because the best, worst and average case is the same. 
			
			In case if there is any break statement, we will be having best case, worst case and everything
			
		4.
		
			int i, j, k, n;
			for(i=1; i<=n; i++) {
				for(j=1; j<=i; j++) {
					for(k=1; k<=100; k++) {
						pf("sugu")
					}
				}
			}
			
			K will be executed 100 times
			j depends on i
			i increment in linear basis
			
			i 1 	2 	3 	4 	5	...n
			j 1 	2 	3 	4 	5	...n
			k 100   200 300 400 500 ...n * 100
			
			So total number of time pf get executed is 
			
			100 + 200 + 300 ... n * 100
			
			100(1 + 2 + 3...n)
			100 (n(n+1)/2)
			which is nothing but 
			
				O(n^2)
				
		5. 
		
			int i, j, k, n;
			for(i=1; i<=n; i++) {
				for(j=1; j<=i^2; j++) {
					for(k=1; k<=n/2; k++) {
						pf("sugu")
					}
				}
			}
			
			i 1 		2 		3 		 ... n
			j 1 		4 		9  		 ... n^2
			k n/2 * 1   n/2 * 4 n/2 * 9  ... n/2 * n^2
			
			so what is that number
			
				n/2 * 1 +  n/2 * 4 + n/2 * 9  ...+  n/2 * n^2
				n/2 (1 + 4 + 9 ... n^2)
				n/2 (n(n+1)(2n+1))/6
				n^4
				O(n^4)
				
		6. 
		
			for(i=1; i<n; i = i * 2)
				pf("sugu")
				
			i = 1, 2, 4 ... n
			
			Let us say it reaches K iteration when i reaches n
			
			
			i is nothing but
			
				2^0, 2^1, 2^2 .... 2^K,
				
			then how many times does it get executed is 
			
				2^K = n
				
				which is nothing but K = log(n) base 2
		
		7. 
		
			int i, j, k, n;
			for(i=n/2; i<=n; i++) {
				for(j=1; j<=n/2; j++) {
					for(k=1; k<=n; k*2) {
						pf("sugu")
					}
				}
			}
		
			i n/2
			j n/2
			k log n
			
			n/2 * n/2 * log n base 2
			
			O(n^2 log n base 2)
		
		8. 
		
			int i, j, k, n;
			for(i=n/2; i<=n; i++) {
				for(j=1; j<=n; j++) {
					for(k=1; k<=n; k*2) {
						pf("sugu")
					}
				}
			}
			
			i n/2
			j log n
			k log n
			
			n/2 * log n base 2 * log n base 2
			
			n/2 * (log n base 2)^2
			
			O(n log n base 2) ^ 2
			
		9. assume n>= 2
		
			while(n>1) {
				n = n/2;
			}
			
			when: 
			
			n = 2(2^1), 4(2^2), 8(2^3)
			exe: 1,		2,		3
			
			so n = 2^K 
			exe: K times
			
			so K = log n base 2
			
			lets say n is not the power of 2 
			
			n = 20 -> 10 -> 5 -> 2 -> 1  which is log 20 base 2
			
			O(log n)base 2
			
			if in question n = n /5, the answer is log n base 5
			
		10. 
		
			for(i=1; i<=n;i++)     ====== n
				for(j=1;j<=n;j=j+i)  ====
					pf("sugu")
			
			i 1
			j 1 to n 
			exe: n times
			
			i 2
			j 1 to n 
			exe: n/2 times
			
			i 3
			j 1 to n 
			exe: n/3 times
			
			.
			.
			.
			
			i k
			j 1 to n 
			exe: n/k times
			
			i n
			j 1 to n 
			exe: n/n times
			
			n(1 + 1/2 + 1/3 + ... 1/n)
			
			n(log n)
			
			O(n(log n))
			
		11.
		
			int n = 2^2^K
			for(i=1; i<=n; i++) {
				j=2
				while(j<=n) {
					j = j^2
					pf("sugu")
				}
			}
			
			k = 1
			n = 4 
			j = 2, 4
			n * 2 times
			
			k = 2
			n = 16 
			j = 2, 4, 16
			n * 3 times
			
			k = 3
			n = 2^8 
			j = 2, 2^2, 2^4, 2^8
			n * 4 times
			
			so the execution
			
			n * (k+1)
			
			n = 2 ^ 2 ^ k
			
			log n = 2 ^ k
			
			log log n = k
			
			n * (log log n + 1)
			
			O(nlog log n)
	Recursive:
	
		